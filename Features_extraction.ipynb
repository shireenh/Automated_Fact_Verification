{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "from pandas import DataFrame\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import collections\n",
    "from collections import Counter\n",
    "import re, math\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from ngram import NGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccard Similarity\n",
    "def jaccardSim(str1, str2): \n",
    "    sent1 = set(str1.split()) \n",
    "    sent2 = set(str2.split())\n",
    "    common_words = sent1.intersection(sent2)\n",
    "    return float(len(common_words)) / (len(sent1) + len(sent2) - len(common_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity -TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineSimTfidf(documents):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "    similarity =cosine_similarity(tfidf_matrix[0:1], tfidf_matrix)\n",
    "    similarity_val = float(similarity[0][1])\n",
    "    return similarity_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longest Common Subsequence (LCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs(s1, s2):\n",
    "    tokens1, tokens2 = s1.split(), s2.split()\n",
    "    cache = collections.defaultdict(dict)\n",
    "    for i in range(-1, len(tokens1)):\n",
    "        for j in range(-1, len(tokens2)):\n",
    "            if i == -1 or j == -1:\n",
    "                cache[i][j] = 0\n",
    "            else:\n",
    "                if tokens1[i] == tokens2[j]:\n",
    "                    cache[i][j] = cache[i - 1][j - 1] + 1\n",
    "                else:\n",
    "                    cache[i][j] = max(cache[i - 1][j], cache[i][j - 1])\n",
    "    return cache[len(tokens1) - 1][len(tokens2) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allen NLP - textual entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "predictor = Predictor.from_path(\"../../Downloads/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allen_score(sent1, sent2):\n",
    "    res = predictor.predict(hypothesis = sent1, premise = sent2)\n",
    "    return res['label_probs']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
